{
  "pretrain_tfrecords": "/mnt/data1/xialang/projects/electra_pretrain_data/pretrain_tfrecords/pretrain_data*",
  "vocab_file": "/mnt/data1/xialang/projects/electra_pretrain_data/vocab.txt",
  "vocab_size": 21128,
  "max_seq_length": 64,
  "model_size": "small",
  "num_train_steps": 60000,
  "save_checkpoints_steps": 1000,
  "train_batch_size": 512,
  "learning_rate": 5e-4,
  "generator_hidden_size": 1.0
}